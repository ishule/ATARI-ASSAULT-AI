Entrenando perceptron para dataset wine...
Epoch 1 - train: 65.8624% val: 66.9456%
Epoch 2 - train: 72.0286% val: 71.5481%
Epoch 3 - train: 64.0751% val: 65.6904%
Epoch 4 - train: 64.8794% val: 65.272%
Epoch 5 - train: 70.0626% val: 72.3849%
Epoch 6 - train: 70.5987% val: 69.8745%
Epoch 7 - train: 65.5049% val: 64.4351%
Epoch 8 - train: 66.8454% val: 66.9456%
Epoch 9 - train: 69.1689% val: 71.1297%
Epoch 10 - train: 70.1519% val: 70.7113%
Epoch 11 - train: 63.807% val: 65.272%
Epoch 12 - train: 70.7775% val: 68.6192%
Epoch 13 - train: 66.4879% val: 66.5272%
Epoch 14 - train: 68.7221% val: 67.364%
Epoch 15 - train: 69.6157% val: 69.8745%
Epoch 16 - train: 69.1689% val: 71.9665%
Epoch 17 - train: 64.7006% val: 64.8536%
Epoch 18 - train: 70.3307% val: 69.8745%
Epoch 19 - train: 68.0071% val: 67.7824%
Epoch 20 - train: 68.9902% val: 68.2008%
Epoch 21 - train: 68.2752% val: 69.0377%
Epoch 22 - train: 63.6282% val: 64.4351%
Epoch 23 - train: 65.1475% val: 65.6904%
Epoch 24 - train: 70.3307% val: 69.4561%
Epoch 25 - train: 67.9178% val: 69.0377%
Epoch 26 - train: 64.3432% val: 64.4351%
Epoch 27 - train: 62.109% val: 64.0167%
Epoch 28 - train: 64.6113% val: 64.4351%
Epoch 29 - train: 68.8114% val: 69.0377%
Epoch 30 - train: 68.0071% val: 67.364%
Epoch 31 - train: 66.0411% val: 67.7824%
Epoch 32 - train: 67.471% val: 68.2008%
Epoch 33 - train: 66.6667% val: 67.7824%
Epoch 34 - train: 67.0241% val: 68.6192%
Epoch 35 - train: 66.9348% val: 68.6192%
Epoch 36 - train: 68.6327% val: 71.1297%
Epoch 37 - train: 66.6667% val: 67.364%
Epoch 38 - train: 66.9348% val: 69.0377%
Epoch 39 - train: 65.8624% val: 67.364%
Epoch 40 - train: 68.0071% val: 70.2929%
Epoch 41 - train: 69.437% val: 68.6192%
Epoch 42 - train: 64.2538% val: 64.4351%
Epoch 43 - train: 67.5603% val: 69.0377%
Epoch 44 - train: 68.6327% val: 70.2929%
Epoch 45 - train: 67.1135% val: 67.364%
Epoch 46 - train: 68.0071% val: 70.7113%
Epoch 47 - train: 65.3262% val: 64.8536%
Epoch 48 - train: 69.0795% val: 69.0377%
Epoch 49 - train: 66.756% val: 66.9456%
Epoch 50 - train: 68.454% val: 69.0377%
Epoch 51 - train: 67.1135% val: 68.2008%
Epoch 52 - train: 65.773% val: 66.1088%
Epoch 53 - train: 73.2797% val: 73.6402%
Epoch 54 - train: 68.0965% val: 67.364%
Epoch 55 - train: 70.3307% val: 71.5481%
Epoch 56 - train: 67.2029% val: 68.2008%
Epoch 57 - train: 68.0071% val: 68.6192%
Epoch 58 - train: 64.4325% val: 65.6904%
Epoch 59 - train: 65.6836% val: 67.364%
Epoch 60 - train: 70.5094% val: 69.4561%
Epoch 61 - train: 64.8794% val: 66.5272%
Epoch 62 - train: 65.8624% val: 67.7824%
Epoch 63 - train: 69.5264% val: 69.8745%
Epoch 64 - train: 65.5943% val: 69.8745%
Epoch 65 - train: 69.9732% val: 71.5481%
Epoch 66 - train: 68.6327% val: 67.364%
Epoch 67 - train: 66.3986% val: 68.2008%
Epoch 68 - train: 68.0071% val: 69.0377%
Epoch 69 - train: 64.6113% val: 66.9456%
Epoch 70 - train: 63.7176% val: 64.4351%
Epoch 71 - train: 69.0795% val: 69.4561%
Epoch 72 - train: 61.8409% val: 66.9456%
Epoch 73 - train: 68.6327% val: 68.2008%
Epoch 74 - train: 69.7945% val: 69.0377%
Epoch 75 - train: 67.6497% val: 69.0377%
Epoch 76 - train: 65.773% val: 67.364%
Epoch 77 - train: 67.2029% val: 67.7824%
Epoch 78 - train: 65.6836% val: 65.272%
Epoch 79 - train: 64.6113% val: 69.4561%
Epoch 80 - train: 70.6881% val: 71.1297%
Epoch 81 - train: 64.7006% val: 66.9456%
Epoch 82 - train: 63.3601% val: 64.4351%
Epoch 83 - train: 64.9687% val: 67.364%
Epoch 84 - train: 70.8668% val: 71.9665%
Epoch 85 - train: 64.5219% val: 65.272%
Epoch 86 - train: 65.8624% val: 65.6904%
Epoch 87 - train: 69.5264% val: 71.5481%
Epoch 88 - train: 68.0965% val: 67.364%
Epoch 89 - train: 66.3986% val: 69.0377%
Epoch 90 - train: 65.2368% val: 66.9456%
Epoch 91 - train: 67.6497% val: 68.2008%
Epoch 92 - train: 68.6327% val: 70.7113%
Epoch 93 - train: 63.4495% val: 61.5063%
Epoch 94 - train: 64.5219% val: 66.5272%
Epoch 95 - train: 63.0027% val: 64.4351%
Epoch 96 - train: 66.3986% val: 62.7615%
Epoch 97 - train: 66.756% val: 69.8745%
Epoch 98 - train: 67.9178% val: 69.4561%
Epoch 99 - train: 66.756% val: 67.7824%


Mejor Modelo:
Precision train: 73.2797% (1119 muestras)
Precision val:   73.6402% (239 muestras)
Precision test:  71.3693% (241 muestras)