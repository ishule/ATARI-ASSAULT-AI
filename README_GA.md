# ğŸ§¬ Algoritmo GenÃ©tico para Redes Neuronales

## Requisitos del Proyecto

Este mÃ³dulo implementa dos niveles de complejidad:

| Nota | Requisito | ImplementaciÃ³n |
|------|-----------|----------------|
| **1.75** | Red Neuronal con pesos entrenados con Algoritmos GenÃ©ticos | âœ… `--mode weights` |
| **2.00** | NeuroevoluciÃ³n: Red Neuronal con evoluciÃ³n de arquitectura Y pesos | âœ… `--mode neuro` |

---

## ğŸ“ Archivos Creados

```
include/GeneticAlgorithm/
â”œâ”€â”€ Individual.hpp       # Representa un individuo (red neuronal)
â””â”€â”€ GeneticAlgorithm.hpp # Algoritmo genÃ©tico principal

src/GeneticAlgorithm/
â”œâ”€â”€ Individual.cpp       # ImplementaciÃ³n del individuo
â””â”€â”€ GeneticAlgorithm.cpp # ImplementaciÃ³n del GA

src/Main/
â””â”€â”€ RunGA.cpp            # Programa principal
```

---

## ğŸ”§ CompilaciÃ³n

AÃ±ade al Makefile:

```makefile
# Algoritmo GenÃ©tico
GA_SRC = src/GeneticAlgorithm/Individual.cpp \
         src/GeneticAlgorithm/GeneticAlgorithm.cpp \
         src/ActivationFunctions.cpp

RunGA: src/Main/RunGA.cpp $(GA_SRC)
	$(CXX) $(CXXFLAGS) -I include -o RunGA $^ -std=c++17
```

O compila manualmente:

```bash
g++ -std=c++17 -O2 -I include \
    src/Main/RunGA.cpp \
    src/GeneticAlgorithm/Individual.cpp \
    src/GeneticAlgorithm/GeneticAlgorithm.cpp \
    src/ActivationFunctions.cpp \
    -o RunGA
```

---

## ğŸš€ Uso

### Modo 1: EvoluciÃ³n de Pesos (Nota 1.75)

La arquitectura es **fija**, solo se evolucionan los pesos.

```bash
# Ejemplo con Iris (4 entradas, 10 neuronas ocultas, 3 salidas)
./RunGA --mode weights \
        --arch 4-10-3 \
        --dataset data/Iris.csv \
        --num-classes 3 \
        --pop 50 \
        --gen 100 \
        --mutation 0.1
```

### Modo 2: NeuroevoluciÃ³n (Nota 2.00)

Se evoluciona **arquitectura Y pesos** simultÃ¡neamente.

```bash
# Ejemplo con Iris
./RunGA --mode neuro \
        --input 4 \
        --output 3 \
        --dataset data/Iris.csv \
        --num-classes 3 \
        --pop 50 \
        --gen 100 \
        --mutation 0.1 \
        --arch-mutation 0.05 \
        --min-layers 1 \
        --max-layers 4 \
        --min-neurons 4 \
        --max-neurons 64
```

---

## âš™ï¸ ParÃ¡metros

### ConfiguraciÃ³n General
| ParÃ¡metro | DescripciÃ³n | Default |
|-----------|-------------|---------|
| `--mode` | `weights` o `neuro` | `weights` |
| `--dataset` | Ruta al CSV | Requerido |
| `--num-classes` | Clases para one-hot | - |
| `--activation` | RELU, SIGMOID, TANH | RELU |
| `--save` | Guardar modelo | - |

### ParÃ¡metros del GA
| ParÃ¡metro | DescripciÃ³n | Default |
|-----------|-------------|---------|
| `--pop` | TamaÃ±o de poblaciÃ³n | 50 |
| `--gen` | Generaciones mÃ¡ximas | 100 |
| `--mutation` | Tasa mutaciÃ³n pesos | 0.1 |
| `--elite` | Ratio de Ã©lite | 0.1 |

### ParÃ¡metros de NeuroevoluciÃ³n
| ParÃ¡metro | DescripciÃ³n | Default |
|-----------|-------------|---------|
| `--arch-mutation` | Tasa mutaciÃ³n arquitectura | 0.05 |
| `--min-layers` | MÃ­nimo capas ocultas | 1 |
| `--max-layers` | MÃ¡ximo capas ocultas | 4 |
| `--min-neurons` | MÃ­nimo neuronas/capa | 4 |
| `--max-neurons` | MÃ¡ximo neuronas/capa | 64 |

---

## ğŸ“Š Diferencias entre Modos

### Modo `weights` (1.75)
```
GeneraciÃ³n 0:  [4-10-3]  [4-10-3]  [4-10-3]  [4-10-3]
                  â†“         â†“         â†“         â†“
                Solo cambian los valores de los pesos
                  â†“         â†“         â†“         â†“
GeneraciÃ³n N:  [4-10-3]  [4-10-3]  [4-10-3]  [4-10-3]
               (misma arquitectura siempre)
```

### Modo `neuro` (2.00)
```
GeneraciÃ³n 0:  [4-10-3]  [4-8-8-3]  [4-20-3]  [4-5-5-5-3]
                  â†“          â†“          â†“          â†“
              Cambian pesos Y arquitectura (capas/neuronas)
                  â†“          â†“          â†“          â†“
GeneraciÃ³n N:  [4-15-8-3]  [4-12-3]  [4-20-10-3]  [4-8-3]
               (arquitecturas evolucionadas)
```

---

## ğŸ”¬ Operadores GenÃ©ticos

### SelecciÃ³n
- **Torneo**: Competencia entre k individuos
- **Ruleta**: Proporcional al fitness
- **Ranking**: Basado en posiciÃ³n
- **Elitismo**: Los mejores pasan directamente

### Crossover (Cruce)
```cpp
// Para cada peso:
if (random() < mutationRate) {
    // MutaciÃ³n: peso aleatorio nuevo
    child.weight = random(-1, 1);
} else {
    // Crossover: hereda de padre o madre
    child.weight = random() < 0.5 ? father.weight : mother.weight;
}
```

### MutaciÃ³n de Arquitectura (solo modo `neuro`)
1. **AÃ±adir neurona** a una capa
2. **Eliminar neurona** de una capa
3. **AÃ±adir capa oculta**
4. **Eliminar capa oculta**

---

## ğŸ“ˆ Ejemplo de Salida

```
========================================
MODO: NEUROEVOLUCIÃ“N (Nota 2.00)
========================================

Entradas: 4
Salidas: 3
Capas ocultas: 1-4
Neuronas/capa: 4-64

Iniciando evoluciÃ³n...
Generaciones mÃ¡ximas: 100
Fitness objetivo: 1e+09

Gen 0 | Best: 45.23 | Avg: 32.15 | Arch: 4-32-18-3 | Params: 826
Gen 1 | Best: 52.10 | Avg: 41.23 | Arch: 4-32-18-3 | Params: 826
Gen 2 | Best: 61.45 | Avg: 48.92 | Arch: 4-45-3 | Params: 318
...
Gen 50 | Best: 96.67 | Avg: 89.23 | Arch: 4-20-10-3 | Params: 293

========================================
RESULTADOS FINALES
========================================
Mejor arquitectura: 4-20-10-3
ParÃ¡metros totales: 293
Fitness final: 96.67
Accuracy Train: 97.50%
Accuracy Test: 96.67%
```

---

## ğŸ® IntegraciÃ³n con Atari (Opcional)

Para usar el GA con el juego Atari Assault, necesitas:

1. Incluir la librerÃ­a ALE (Arcade Learning Environment)
2. Implementar `calculateGameFitness()` en `Individual.cpp`

```cpp
double Individual::calculateGameFitness(int maxSteps) {
    ALEInterface ale;
    ale.loadROM("assets/assault.bin");
    
    double totalReward = 0;
    int steps = 0;
    
    while (!ale.game_over() && steps < maxSteps) {
        // Obtener estado de la RAM
        auto state = getStateFromRAM(ale);
        
        // Predecir acciÃ³n
        auto output = predict(state);
        
        // Ejecutar acciÃ³n
        totalReward += ale.act(actionFromOutput(output));
        steps++;
    }
    
    fitness_ = totalReward;
    return fitness_;
}
```

---

## ğŸ“š Referencias

- **NEAT**: NeuroEvolution of Augmenting Topologies (Stanley & Miikkulainen, 2002)
- **Genetic Algorithms**: Holland, 1975
- Tu implementaciÃ³n original en `Atari Assault/atariAssault_IA-master/`
